{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 임베딩 벡터:\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "\n",
      "RoPE 적용 후 회전된 임베딩 벡터:\n",
      "[[ 0  2  3]\n",
      " [ 2  5  6]\n",
      " [ 4  9  9]\n",
      " [ 4 14 12]]\n"
     ]
    }
   ],
   "source": [
    "#초기 코드\n",
    "import numpy as np\n",
    "\n",
    "# RoPE에서 사용할 주기적 회전 변환 함수\n",
    "def apply_rotary_position_embedding(embedding, position, theta):\n",
    "    \"\"\"\n",
    "    임베딩 벡터에 대한 회전 변환을 적용하는 함수\n",
    "    :param embedding: 각 토큰의 임베딩 벡터 (numpy array)\n",
    "    :param position: 토큰의 위치 (p 값)\n",
    "    :param theta: 회전 각도\n",
    "    :return: 회전 변환된 임베딩 벡터\n",
    "    \"\"\"\n",
    "    embedding_rotated = np.zeros_like(embedding)\n",
    "    \n",
    "    cos_theta = np.cos(position * theta)\n",
    "    sin_theta = np.sin(position * theta)\n",
    "    \n",
    "    # 회전 변환 적용: 짝수와 홀수 차원을 쌍으로 묶어 회전\n",
    "    for i in range(0, len(embedding) - 1, 2):\n",
    "        embedding_rotated[i] = cos_theta * embedding[i] - sin_theta * embedding[i + 1]\n",
    "        embedding_rotated[i + 1] = sin_theta * embedding[i] + cos_theta * embedding[i + 1]\n",
    "    \n",
    "    # 홀수 차원이 남으면, 그대로 유지\n",
    "    if len(embedding) % 2 == 1:\n",
    "        embedding_rotated[-1] = embedding[-1]\n",
    "\n",
    "    return embedding_rotated\n",
    "\n",
    "# 예시 토큰 임베딩 벡터 (4개의 토큰, 3차원 임베딩)\n",
    "embeddings = np.array([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9],\n",
    "                       [10, 11, 12]])\n",
    "\n",
    "# 임베딩 차원 (임베딩 벡터의 길이)와 토큰 수 정의\n",
    "embedding_dim = 3\n",
    "num_tokens = embeddings.shape[0]\n",
    "\n",
    "# 회전 각도를 설정 (임베딩 차원에 따라 각도를 다르게 설정할 수 있음)\n",
    "theta = 0.1  # 예시로 작은 각도 설정\n",
    "\n",
    "# 토큰마다 RoPE 적용\n",
    "rotated_embeddings = []\n",
    "for p in range(1, num_tokens + 1):\n",
    "    rotated_embedding = apply_rotary_position_embedding(embeddings[p-1], p, theta)\n",
    "    rotated_embeddings.append(rotated_embedding)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"원래 임베딩 벡터:\")\n",
    "print(embeddings)\n",
    "print(\"\\nRoPE 적용 후 회전된 임베딩 벡터:\")\n",
    "print(np.array(rotated_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#넘파이로 구현한 RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 x_np:\n",
      "[[[ 1.7640524   0.4001572   0.978738   ...  1.4693588   0.15494743\n",
      "    0.37816253]\n",
      "  [-0.88778573 -1.9807965  -0.34791216 ... -0.35955316 -0.8131463\n",
      "   -1.7262826 ]\n",
      "  [ 0.17742614 -0.40178093 -1.6301984  ...  0.97663903  0.3563664\n",
      "    0.7065732 ]\n",
      "  ...\n",
      "  [ 0.61334914  1.8436999   0.27109098 ... -0.8586684   0.4361871\n",
      "    1.5714631 ]\n",
      "  [ 1.0773149   0.8110897  -2.2315376  ... -0.94772434  1.3992299\n",
      "   -0.22612372]\n",
      "  [-1.4388542   0.801301   -0.00333145 ...  0.46387276  0.6176608\n",
      "    2.496417  ]]]\n",
      "NumPy freqs: (16,)\n",
      "== NumPy RotaryEmbedding 호출 ==\n",
      "== NumPy get_angles ==\n",
      "positions: (128,)\n",
      "freqs before repeat: (128, 16)\n",
      "freqs after repeat: (128, 32)\n",
      "freqs after adding batch dimension: (1, 128, 32)\n",
      "== NumPy apply_rotary_embedding ==\n",
      "입력 t: (1, 128, 32)\n",
      "freqs: (1, 128, 32)\n",
      "t_left: (1, 128, 0)\n",
      "t_middle: (1, 128, 32)\n",
      "t_right: (1, 128, 0)\n",
      "== NumPy rotate_half ==\n",
      "입력 x: (1, 128, 32)\n",
      "reshaped x: (1, 128, 16, 2)\n",
      "x1: (1, 128, 16)\n",
      "x2: (1, 128, 16)\n",
      "stacked x: (1, 128, 16, 2)\n",
      "최종 x: (1, 128, 32)\n",
      "t_transformed: (1, 128, 32)\n",
      "최종 결과: (1, 128, 32)\n",
      "NumPy 결과 x_rotated_np: (1, 128, 32)\n",
      "NumPy 결과 x_rotated_np:\n",
      "[[[ 1.7640524   0.4001572   0.978738   ...  1.4693588   0.15494743\n",
      "    0.37816253]\n",
      "  [ 1.1871102  -1.8172748  -0.3776972  ... -0.35976577 -0.8128393\n",
      "   -1.7264272 ]\n",
      "  [ 0.291503    0.328533   -1.1208601  ...  0.9767706   0.35611507\n",
      "    0.70669985]\n",
      "  ...\n",
      "  [ 1.6189378   1.0744613  -0.94587505 ... -0.8082858   0.40115094\n",
      "    1.5807698 ]\n",
      "  [ 0.749316    1.1211598   0.47528556 ... -0.9412385   1.4039448\n",
      "   -0.19471799]\n",
      "  [-1.1137004  -1.2132834   0.07436568 ...  0.49931133  0.5611287\n",
      "    2.5097287 ]]]\n",
      "PyTorch 결과 x_rotated_torch: (1, 128, 32)\n",
      "PyTorch 결과 x_rotated_torch:\n",
      "[[[ 1.7640524   0.4001572   0.978738   ...  1.4693588   0.15494743\n",
      "    0.37816253]\n",
      "  [ 1.1871101  -1.8172748  -0.3776972  ... -0.35976577 -0.8128393\n",
      "   -1.7264272 ]\n",
      "  [ 0.291503    0.328533   -1.1208601  ...  0.9767706   0.35611507\n",
      "    0.70669985]\n",
      "  ...\n",
      "  [ 1.6189377   1.0744612  -0.94587505 ... -0.8082858   0.40115094\n",
      "    1.5807698 ]\n",
      "  [ 0.749316    1.1211598   0.47528556 ... -0.9412385   1.4039448\n",
      "   -0.19471799]\n",
      "  [-1.1137004  -1.2132834   0.07436568 ...  0.49931133  0.5611287\n",
      "    2.5097287 ]]]\n",
      "두 구현 간의 최대 차이: 2.384185791015625e-07\n",
      "NumPy와 PyTorch 구현 결과 차이 벡터:\n",
      "[[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [1.1920929e-07 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [1.1920929e-07 1.1920929e-07 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "NumPy와 PyTorch 구현 결과가 일치합니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pytest\n",
    "from TorchRotrayEmbedding import RotaryEmbedding\n",
    "\n",
    "def numpy_rotate_half(x):\n",
    "    print(\"== NumPy rotate_half ==\")\n",
    "    print(\"입력 x:\", x.shape)\n",
    "    x = x.reshape(*x.shape[:-1], -1, 2)\n",
    "    print(\"reshaped x:\", x.shape)\n",
    "    x1 = x[..., 0]\n",
    "    x2 = x[..., 1]\n",
    "    print(\"x1:\", x1.shape)\n",
    "    print(\"x2:\", x2.shape)\n",
    "    x = np.stack((-x2, x1), axis=-1)\n",
    "    print(\"stacked x:\", x.shape)\n",
    "    x = x.reshape(*x.shape[:-2], -1)\n",
    "    print(\"최종 x:\", x.shape)\n",
    "    return x\n",
    "\n",
    "def numpy_apply_rotary_embedding(freqs, t, start_index=0, scale=1.0):\n",
    "    print(\"== NumPy apply_rotary_embedding ==\")\n",
    "    print(\"입력 t:\", t.shape)\n",
    "    print(\"freqs:\", freqs.shape)\n",
    "    t_left = t[..., :start_index]\n",
    "    end_index = start_index + freqs.shape[-1]\n",
    "    t_middle = t[..., start_index:end_index]\n",
    "    t_right = t[..., end_index:]\n",
    "    print(\"t_left:\", t_left.shape)\n",
    "    print(\"t_middle:\", t_middle.shape)\n",
    "    print(\"t_right:\", t_right.shape)\n",
    "    t_transformed = (t_middle * np.cos(freqs) * scale) + (numpy_rotate_half(t_middle) * np.sin(freqs) * scale)\n",
    "    print(\"t_transformed:\", t_transformed.shape)\n",
    "    result = np.concatenate((t_left, t_transformed, t_right), axis=-1)\n",
    "    print(\"최종 결과:\", result.shape)\n",
    "    return result\n",
    "\n",
    "class NumpyRotaryEmbedding:\n",
    "    def __init__(self, dim, theta=10000):\n",
    "        self.dim = dim\n",
    "        self.theta = theta\n",
    "        # PyTorch 구현과 동일하게 freqs 계산\n",
    "        self.freqs = 1.0 / (theta ** (np.arange(0, dim, 2, dtype=np.float32) / dim))\n",
    "        print(\"NumPy freqs:\", self.freqs.shape)\n",
    "\n",
    "    def get_angles(self, seq_len, offset=0):\n",
    "        print(\"== NumPy get_angles ==\")\n",
    "        positions = (np.arange(seq_len, dtype=np.float32) + offset)\n",
    "        print(\"positions:\", positions.shape)\n",
    "        freqs = np.outer(positions, self.freqs)\n",
    "        print(\"freqs before repeat:\", freqs.shape)\n",
    "        freqs = np.repeat(freqs, repeats=2, axis=-1)\n",
    "        print(\"freqs after repeat:\", freqs.shape)\n",
    "        return freqs.astype(np.float32)\n",
    "\n",
    "    def __call__(self, x, offset=0):\n",
    "        print(\"== NumPy RotaryEmbedding 호출 ==\")\n",
    "        seq_len = x.shape[1]\n",
    "        freqs = self.get_angles(seq_len, offset=offset)\n",
    "        freqs = freqs[None, :, :]  # (1, seq_len, dim)\n",
    "        print(\"freqs after adding batch dimension:\", freqs.shape)\n",
    "        return numpy_apply_rotary_embedding(freqs, x)\n",
    "\n",
    "@pytest.mark.parametrize(\"batch_size\", [4, 8, 12])\n",
    "@pytest.mark.parametrize(\"seq_len\", [128, 256])\n",
    "@pytest.mark.parametrize(\"dim\", [64, 128])\n",
    "def test_rope(batch_size, seq_len, dim):\n",
    "    # 입력 데이터 생성\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    x_np = np.random.randn(batch_size, seq_len, dim).astype(np.float32)\n",
    "    x_torch = torch.from_numpy(x_np).float()\n",
    "\n",
    "    print(\"입력 데이터 x_np:\")\n",
    "    print(x_np)\n",
    "\n",
    "    # NumPy 기반 RoPE 적용\n",
    "    numpy_rope = NumpyRotaryEmbedding(dim=dim)\n",
    "    x_rotated_np = numpy_rope(x_np)\n",
    "    print(\"NumPy 결과 x_rotated_np:\", x_rotated_np.shape)\n",
    "    print(\"NumPy 결과 x_rotated_np:\")\n",
    "    print(x_rotated_np)\n",
    "\n",
    "    # PyTorch 기반 RoPE 적용\n",
    "    torch_rope = RotaryEmbedding(dim=dim)\n",
    "    x_rotated_torch = torch_rope.rotate_queries_or_keys(x_torch)\n",
    "    x_rotated_torch = x_rotated_torch.detach().numpy()\n",
    "    print(\"PyTorch 결과 x_rotated_torch:\", x_rotated_torch.shape)\n",
    "    print(\"PyTorch 결과 x_rotated_torch:\")\n",
    "    print(x_rotated_torch)\n",
    "\n",
    "    # 결과 비교\n",
    "    difference = np.max(np.abs(x_rotated_np - x_rotated_torch))\n",
    "    print(f\"두 구현 간의 최대 차이: {difference}\")\n",
    "    print(\"NumPy와 PyTorch 구현 결과 차이 벡터:\")\n",
    "    print(x_rotated_np - x_rotated_torch)\n",
    "    assert np.allclose(x_rotated_np, x_rotated_torch, atol=1e-6), f\"NumPy와 PyTorch 구현 결과가 일치하지 않습니다. 최대 차이: {difference}\"\n",
    "\n",
    "    print(\"NumPy와 PyTorch 구현 결과가 일치합니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_rope(1, 128, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-transformer-hybrid-model-fa1p7jlT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
